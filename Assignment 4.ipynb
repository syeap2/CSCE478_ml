{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "#Linear_SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = load_iris()\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "df = pd.DataFrame(np.c_[X,y], columns=data['feature_names']+['target'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     petal length (cm)  petal width (cm)  target\n",
       "145                5.2               2.3     1.0\n",
       "146                5.0               1.9     1.0\n",
       "147                5.2               2.0     1.0\n",
       "148                5.4               2.3     1.0\n",
       "149                5.1               1.8     1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns='sepal length (cm)')\n",
    "df = df.drop(columns='sepal width (cm)')\n",
    "\n",
    "# Categorize the target at good quality wine (1) or bad quality wine (0)\n",
    "def categorizeQualityData(dataFrame, columnName):\n",
    "    for i in range(dataFrame.shape[0]):\n",
    "        if dataFrame[columnName][i] == 2:\n",
    "            dataFrame[columnName][i] = 1\n",
    "        else:\n",
    "            dataFrame[columnName][i] = 0  \n",
    "    return \n",
    "\n",
    "categorizeQualityData(df, 'target')\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     petal length (cm)  petal width (cm)  target\n",
       "13                 1.1               0.1     0.0\n",
       "128                5.6               2.1     1.0\n",
       "25                 1.6               0.2     0.0\n",
       "92                 4.0               1.2     0.0\n",
       "68                 4.5               1.5     0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3\n",
    "def standardizeData(dataSet):\n",
    "    for key, values in dataSet.iteritems():\n",
    "        mean = dataSet[key].mean()\n",
    "        std = dataSet[key].std()\n",
    "        if key != 'target':\n",
    "            dataSet[key] = (dataSet[key] - mean) / std\n",
    "    return dataSet\n",
    "\n",
    "standardizeData = standardizeData(df)\n",
    "\n",
    "# Splitting the data into Train Set and Test Set\n",
    "def partition(X,y,t):\n",
    "    x_train = np.array(X[int((len(X)+1)*t):])\n",
    "    x_test = np.array(X[:int((len(X)+1)*t)])\n",
    "    y_train = np.array(y[int((len(y)+1)*t):])\n",
    "    y_test = np.array(y[:int((len(y)+1)*t)]) \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "#separate the target vector and features\n",
    "def separateTargetVector(dataSet):\n",
    "    y = dataSet['target'] #target vector\n",
    "    X = dataSet.drop(columns='target') #features matrix\n",
    "    return X,y\n",
    "\n",
    "#a function to split data into partition\n",
    "#according to the number of folds\n",
    "def partitionSplit(df, folds):\n",
    "    s_partition = []\n",
    "    dfCopy = df\n",
    "    #set the size for each partiton\n",
    "    eachPartition = int(df.shape[0] / folds)\n",
    "    for i in range(folds):\n",
    "        partition = []\n",
    "        #going through each partition\n",
    "        for j in range(eachPartition):\n",
    "            if(len(partition) < eachPartition):\n",
    "                value = dfCopy.index[0]\n",
    "                partition.append(value.tolist())\n",
    "                dfCopy = dfCopy.drop(value)\n",
    "        s_partition.append((np.asarray(partition)).tolist())\n",
    "  \n",
    "    return s_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4\n",
    "\n",
    "#function for the s-fold validation\n",
    "def sFold(folds, data, labels, model, error_function, dictionary): \n",
    "    avgAccuracy = [] \n",
    "    value = []\n",
    "    splitX = partitionSplit(data, folds)\n",
    "    minError = 100.0\n",
    "    \n",
    "    #loop to choose a partition as validation set\n",
    "    for i, partition in enumerate(splitX):\n",
    "        trainSet = list(splitX)\n",
    "        del(trainSet[i])       #dropping the validation set\n",
    "        trainSet = sum(trainSet, [])\n",
    "\n",
    "        testSet = []           #getting the validation set \n",
    "        for row in partition:\n",
    "            testSet.append(row)  #put data in validation set into a new list \n",
    "            \n",
    "        #splitting the data into train and test set\n",
    "        xTrainValues = []\n",
    "        yTrainValues = []        \n",
    "        for trainIndex in trainSet:\n",
    "            xTrainValues.append(data.loc[trainIndex])\n",
    "            yTrainValues.append(labels.loc[trainIndex])\n",
    "\n",
    "        #splitting the validation set data into train and test set\n",
    "        xTestValues = []\n",
    "        yTestValues = []\n",
    "        for testIndex in testSet:\n",
    "            xTestValues.append(data.loc[testIndex])\n",
    "            yTestValues.append(labels.loc[testIndex])\n",
    "    \n",
    "        #preform prediction using Softmax Regression\n",
    "        if model == 'Linear_SVC':\n",
    "            modelClassifier = Linear_SVC(C=1, max_iter=100, tol=None, learning_rate=‘constant’,learning_rate_init=0.001, t_0=1, t_1=1000, early_stopping=False, validation_fraction=0.1)\n",
    "            modelClassifier.fit(np.array(xTrainValues), np.array(yTrainValues))\n",
    "            yPredict= modelClassifier.predict(np.array(xTestValues))\n",
    "            \n",
    "            #calculating the error using mse score\n",
    "            if error_function == \"accuracy\":\n",
    "                accuracy_value = accuracy(yPredict, np.array(yTestValues))\n",
    "                avgAccuracy.append(accuracy_value)\n",
    "                \n",
    "    avgFinalAccuracy = sum(avgAccuracy)/folds\n",
    "    if(avgFinalAccuracy < minError):\n",
    "        minError = avgFinalAccuracy\n",
    "\n",
    "    return minError\n",
    "    \n",
    "    \n",
    "#function to pass the hyperparameter into s-fold validation\n",
    "def dictionary(lambd, tol, learning_rate, regularizer):\n",
    "    result = []\n",
    "    model = []\n",
    "    modelArgs = dict()\n",
    "    #form the dictionary\n",
    "    for eachLambd in lambd:\n",
    "        for eachTol in tol:\n",
    "            for eachLearningRate in learning_rate:\n",
    "                for eachRegularizer in regularizer:\n",
    "                    modelArgs = {'lambd' : eachLambd, 'tol' : eachTol, 'learning_rate' : eachLearningRate,'regularizer': eachRegularizer}\n",
    "                    #use of s-folds\n",
    "                    accuracy = sFold(5, X, y, 'Linear_SVC', 'accuracy', modelArgs)\n",
    "                    result.append(accuracy)\n",
    "                    model.append(modelArgs)\n",
    "\n",
    "    acc = np.array(result)\n",
    "    best_args = model[acc.argmax()]\n",
    "    return best_args\n",
    "    \n",
    "#get the X data(features without target) and y data(target column)\n",
    "X,y = separateTargetVector(standardizeData)\n",
    "\n",
    "C = []\n",
    "learning_rate = []\n",
    "learning_rate_init(when ‘constant’ learning_rate is used)\n",
    "max_iter = []\n",
    "tol = []\n",
    "\n",
    "best_args = dictionary()\n",
    "print(best_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5\n",
    "X,y = separateTargetVector(standardizeData)\n",
    "xTrain, xTest, yTrain, yTest = partition(X, y, 0.2)\n",
    "modelClassifier = Linear_SVC(C=1, max_iter=100, tol=None, learning_rate=‘constant’,learning_rate_init=0.001, t_0=1, t_1=1000, early_stopping=False, validation_fraction=0.1)\n",
    "modelClassifier.fit(xTrain, yTrain)\n",
    "yPredict = modelClassifier.predict(xTest)\n",
    "yPredict = np.array(yPredict)\n",
    "\n",
    "print('Accuracy:', accuracy(yPredict, yTest))\n",
    "print('Confusion Matrix:', confusionMatrix(yTest, yPredict))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def partitionSplit(trainSetSize, folds):\n",
    "    s_partition = []\n",
    "    dfCopy = df\n",
    "    #set the size for each partiton\n",
    "    eachPartition = int(len(trainSetSize) / folds)\n",
    "    for i in range(folds):\n",
    "        partition = []\n",
    "        #going through each partition\n",
    "        for j in range(eachPartition):\n",
    "            if(len(partition) < eachPartition):\n",
    "                value = dfCopy.index[0]\n",
    "                partition.append(value.tolist())\n",
    "                dfCopy = dfCopy.drop(value)\n",
    "        s_partition.append((np.asarray(partition)).tolist())\n",
    "  \n",
    "    return s_partition\n",
    "\n",
    "def trainDataSize(df, train_size):\n",
    "    s_partition = []\n",
    "    trainSize = train_size\n",
    "    dataSize = int(df.shape[0])\n",
    "\n",
    "    while trainSize < dataSize:\n",
    "        partition = []\n",
    "        for i in range(trainSize):\n",
    "            if(len(partition) < trainSize):\n",
    "                    value = df.index[i]\n",
    "                    partition.append(value.tolist())\n",
    "        s_partition.append((np.asarray(partition)).tolist())\n",
    "        trainSize+=train_size\n",
    "  \n",
    "    return s_partition\n",
    "\n",
    "def learning_curve(model, X, Y, cv, train_size=10, learning_rate=0.01, epochs=1000, tol=None, regularizer=None, lambd=0.0):\n",
    "    finalTrainErrorSet = []\n",
    "    finalValidationErrorSet = []\n",
    "    trainSetSize = trainDataSize(X, train_size)\n",
    "    \n",
    "    for i in range(len(trainSetSize)):\n",
    "        x = trainSetSize[i]\n",
    "        splitX = partitionSplit(x, cv)\n",
    "        train_scores = [] \n",
    "        val_scores = []\n",
    "        #loop to choose a partition as validation set\n",
    "        for i, partition in enumerate(splitX):\n",
    "            trainSet = list(splitX)\n",
    "\n",
    "            del(trainSet[i])       #dropping the validation set\n",
    "            trainSet = sum(trainSet, [])\n",
    "\n",
    "            validationSet = []           #getting the validation set \n",
    "            for row in partition:\n",
    "                validationSet.append(row)  #put data in validation set into a new list\n",
    "\n",
    "            #splitting the data into train and test set\n",
    "            xTrainValues = []\n",
    "            yTrainValues = []     \n",
    "            for trainIndex in trainSet:\n",
    "                xTrainValues.append(X.loc[trainIndex])\n",
    "                yTrainValues.append(Y.loc[trainIndex])\n",
    "\n",
    "            #splitting the validation set data into train and test set\n",
    "            xValidationValues = []\n",
    "            yValidationValues = []\n",
    "            for testIndex in validationSet:\n",
    "                xValidationValues.append(X.loc[testIndex])\n",
    "                yValidationValues.append(Y.loc[testIndex])\n",
    "                \n",
    "            #perform prediction using Linear Regression\n",
    "            if model == 'Linear_Regression':\n",
    "                modelRegression = Linear_Regression()\n",
    "                modelRegression.fit(np.array(xTrainValues), np.array(yTrainValues), learning_rate, epochs, tol, regularizer,lambd)\n",
    "                \n",
    "                yTestPredict = modelRegression.predict(np.array(xValidationValues))\n",
    "                validation_error = math.sqrt(mse(yValidationValues, yTestPredict))\n",
    "                val_scores.append(validation_error)\n",
    "                \n",
    "                yTrainPredict = modelRegression.predict(np.array(xTrainValues))\n",
    "                train_error = math.sqrt(mse(yTrainValues, yTrainPredict))\n",
    "                train_scores.append(train_error)\n",
    "                \n",
    "        avgFinalTrainError = sum(train_scores)/cv\n",
    "        finalTrainErrorSet.append(avgFinalTrainError)\n",
    "        \n",
    "        avgFinalValidationError = sum(val_scores)/cv\n",
    "        finalValidationErrorSet.append(avgFinalValidationError)\n",
    "        \n",
    "    return finalTrainErrorSet, finalValidationErrorSet\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "X,y = separateTargetVector(standardizeData)\n",
    "trainSize = 20\n",
    "train_scores, val_scores= learning_curve(\"Linear_Regression\", X, y, 5, train_size=trainSize, learning_rate=0.01, \n",
    "                                          epochs=1000, tol=None, regularizer=\"l2\", lambd=0.0001)\n",
    "\n",
    "x = []\n",
    "i = trainSize\n",
    "while i < len(X):\n",
    "    x.append(i)\n",
    "    i = i + trainSize\n",
    "\n",
    "#Plotting\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, val_scores, color='red', linewidth=5, linestyle='--')\n",
    "plt.plot(x, train_scores, color='blue', linewidth=5, linestyle='--') \n",
    "plt.title('Best Model Plot')\n",
    "plt.xlabel('Traning Set Data')\n",
    "plt.ylabel('RSME')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7\n",
    "#plot decision boundary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
